xMAR    <- x
xMAR[which(rbinom(1000, 1, ifelse(x[, 2] < 10, 0.02, 0.2)) == 1), 1] <- NA
xMAR[which(is.na(xMAR[, 1])), 1] <- mean(xMAR[, 1], na.rm = TRUE)
cor(xMAR)
xMAR    <- x
xMAR[which(rbinom(1000, 1, ifelse(x[, 2] < 10, 0.02, 0.2)) == 1), 1] <- NA
xMAR[which(is.na(xMAR[, 1])), 1] <- mean(xMAR[, 1], na.rm = TRUE)
cor(xMAR)
xMAR    <- x
xMAR[which(rbinom(1000, 1, ifelse(x[, 2] < 10, 0.02, 0.2)) == 1), 1] <- NA
xMAR[which(is.na(xMAR[, 1])), 1] <- mean(xMAR[, 1], na.rm = TRUE)
cor(xMAR)
xMNAR    <- x
xMNAR[which(rbinom(1000, 1, ifelse(x[, 1] < 5, 0.02, 0.2)) == 1), 1] <- NA
xMNAR[which(is.na(xMNAR[, 1])), 1] <- mean(xMNAR[, 1], na.rm = TRUE)
cor(xMNAR)
xMNAR    <- x
xMNAR[which(rbinom(1000, 1, ifelse(x[, 1] < 5, 0.02, 0.2)) == 1), 1] <- NA
xMNAR[which(is.na(xMNAR[, 1])), 1] <- mean(xMNAR[, 1], na.rm = TRUE)
cor(xMNAR)
xMNAR    <- x
xMNAR[which(rbinom(1000, 1, ifelse(x[, 1] < 5, 0.02, 0.2)) == 1), 1] <- NA
xMNAR[which(is.na(xMNAR[, 1])), 1] <- mean(xMNAR[, 1], na.rm = TRUE)
cor(xMNAR)
xMNAR    <- x
xMNAR[which(rbinom(1000, 1, ifelse(x[, 1] < 5, 0.02, 0.2)) == 1), 1] <- NA
xMNAR[which(is.na(xMNAR[, 1])), 1] <- mean(xMNAR[, 1], na.rm = TRUE)
cor(xMNAR)
xMNAR    <- x
xMNAR[which(rbinom(1000, 1, ifelse(x[, 1] < 5, 0.02, 0.2)) == 1), 1] <- NA
xMNAR[which(is.na(xMNAR[, 1])), 1] <- mean(xMNAR[, 1], na.rm = TRUE)
cor(xMNAR)
xMNAR    <- x
xMNAR[which(rbinom(1000, 1, ifelse(x[, 1] < 5, 0.02, 0.2)) == 1), 1] <- NA
xMNAR[which(is.na(xMNAR[, 1])), 1] <- mean(xMNAR[, 1], na.rm = TRUE)
cor(xMNAR)
xMNAR    <- x
xMNAR[which(rbinom(1000, 1, ifelse(x[, 1] < 5, 0.02, 0.2)) == 1), 1] <- NA
xMNAR[which(is.na(xMNAR[, 1])), 1] <- mean(xMNAR[, 1], na.rm = TRUE)
cor(xMNAR)
xMNAR    <- x
xMNAR[which(rbinom(1000, 1, ifelse(x[, 1] < 5, 0.02, 0.2)) == 1), 1] <- NA
xMNAR[which(is.na(xMNAR[, 1])), 1] <- mean(xMNAR[, 1], na.rm = TRUE)
cor(xMNAR)
xMNAR    <- x
xMNAR[which(rbinom(1000, 1, ifelse(x[, 1] < 5, 0.02, 0.2)) == 1), 1] <- NA
xMNAR[which(is.na(xMNAR[, 1])), 1] <- mean(xMNAR[, 1], na.rm = TRUE)
cor(xMNAR)
xMNAR    <- x
xMNAR[which(rbinom(1000, 1, ifelse(x[, 1] < 5, 0.02, 0.2)) == 1), 1] <- NA
xMNAR[which(is.na(xMNAR[, 1])), 1] <- mean(xMNAR[, 1], na.rm = TRUE)
cor(xMNAR)
xMNAR    <- x
xMNAR[which(rbinom(1000, 1, ifelse(x[, 1] < 5, 0.02, 0.2)) == 1), 1] <- NA
xMNAR[which(is.na(xMNAR[, 1])), 1] <- mean(xMNAR[, 1], na.rm = TRUE)
cor(xMNAR)
var(x)
xMCAR   <- x
xMCAR[sample(1:1000, 100), 1] <- NA
xMCAR[which(is.na(xMCAR[, 1])), 1] <- mean(xMCAR[, 1], na.rm = TRUE)
cor(xMCAR)
var(xMCAR)
xMAR    <- x
xMAR[which(rbinom(1000, 1, ifelse(x[, 2] < 10, 0.02, 0.2)) == 1), 1] <- NA
xMAR[which(is.na(xMAR[, 1])), 1] <- mean(xMAR[, 1], na.rm = TRUE)
cor(xMAR)
var(xMAR)
xMNAR    <- x
xMNAR[which(rbinom(1000, 1, ifelse(x[, 1] < 5, 0.02, 0.2)) == 1), 1] <- NA
xMNAR[which(is.na(xMNAR[, 1])), 1] <- mean(xMNAR[, 1], na.rm = TRUE)
cor(xMNAR)
var(xMNAR)
library(poolR)
?fisher
k1 <- 7
k2 <- 2
pval1 <- .02
pval2 <- .10
pvals <- c(rep(pval1, k1), rep(pval2, k2))
pval12 <- c(pval1, pval2)
R <- bldiag(matrix(1, nrow=k1, ncol=k1), matrix(1, nrow=k2, ncol=k2))
library(metafor)
library(Matrix)
library(MASS)
library(poolR)
k1 <- 7
k2 <- 2
pval1 <- .02
pval2 <- .10
pvals <- c(rep(pval1, k1), rep(pval2, k2))
pval12 <- c(pval1, pval2)
R <- bldiag(matrix(1, nrow=k1, ncol=k1), matrix(1, nrow=k2, ncol=k2))
pvals
pval12
R
meff(R, method="nyholt")
meff(R, method="liji")
meff(R, method="gao")
meff(R, method="galwey")
fisher(pvals, adjust="liji", R=R)
fisher(pval12)
invchisq(pvals, adjust="liji", R=R)
invchisq(pval12)
stouffer(pvals, adjust="liji", R=R)
stouffer(pval12)
binotest(pvals, adjust="liji", R=R)
binotest(pval12)
bonferroni(pvals, adjust="liji", R=R)
bonferroni(pval12)
tippett(pvals, adjust="liji", R=R)
tippett(pval12)
k1 <- 9
k2 <- 4
R <- bldiag(matrix(1, nrow=k1, ncol=k1), matrix(1, nrow=k2, ncol=k2))
R
meff(R, method="nyholt")
meff(R, method="liji")
meff(R, method="gao")
meff(R, method="galwey")
# in this case galwey does not give the correct result, 2.
# calculating the galwey correction.
evs <- eigen(R)$values
evs
round(evs, 2) # eigen values seem to be correct.
# in this case galwey does not give the correct result, 2.
# calculating the galwey correction.
evs <- eigen(R)$values
evs
round(evs, 2) # eigen values seem to be correct.
evs[evs < 0] <- 0
evs
m <- sum(sqrt(evs))^2/sum(evs)
m
m # m is not equal to 2. And, it is smaller than 2.
# sure if we can get the correct result in every case. Probably, it will not work
# correctly in every case. For example, if k1 = 30 and k2 = 2, it doesn't give the
# correct result even with the round() function.
ceiling(m) # ceiling() also gives the result.
68650 / 60
68650 / 60 /60
library(metafor)
?AIC
?AIC.rma
rm(list=ls())
k.studies   <- c(20, 50, 100, 200)
k.species   <- c(5, 10, 50, 100)
sigma2.n    <- c(0.1, 0.3, 0.7, 0.9)
sigma2.p    <- c(0.1, 0.3, 0.7, 0.9)
sigma2.s    <- c(0.1, 0.3, 0.7, 0.9)
sigma2.e    <- c(0.1, 0.3, 0.7, 0.9)
vi.fac      <- c(1.0)
tree.power  <- c(0.1, 1, 5)
### 11.09.2018 - adding a factor for effect size
beta        <- c(0, 0.3, 0.5, 0.9)
### 11.09.2018 - adding a factor for effect size
allconds    <- expand.grid(k.studies = k.studies, k.species = k.species, sigma2.n = sigma2.n,
sigma2.p = sigma2.p, sigma2.s = sigma2.s, sigma2.e = sigma2.e,
vi.fac = vi.fac, tree.power = tree.power, beta = beta)
allconds    <- allconds[allconds$k.studies > allconds$k.species, ]
library(metafor)
library(ape)
library(MASS)
j <- 1
cond  <- allconds[j,]
### 09.10.2018 - discarding the initial points for the models other than model 15.
### initial points for model 3 in Nakagawa & Santos (2012).
# control3  <- list(optimizer="nlminb", sigma2.init=c(cond$sigma2.e))
control3  <- list(optimizer="nlminb")
### initial points for model 6 in Nakagawa & Santos (2012).
# control6 <- list(optimizer="nlminb", sigma2.init=c(cond$sigma2.s, cond$sigma2.e))
control6  <- list(optimizer="nlminb")
### initial points for model 8 in Nakagawa & Santos (2012).
# control8  <- list(optimizer="nlminb", sigma2.init=c(cond$sigma2.n, cond$sigma2.s, cond$sigma2.e))
control8  <- list(optimizer="nlminb")
### initial points for model 15 in Nakagawa & Santos (2012).
control15 <- list(optimizer="nlminb", sigma2.init=c(cond$sigma2.n, cond$sigma2.p, cond$sigma2.s, cond$sigma2.e))
l <- 1
m <- 0
m <- m + 1
# 20.07.2018 - Ozan added here set.seed() function by putting m inside of it
# for reproducibility.
set.seed(m)
### simulate k for each study
min.k.per.study <- rep(1, cond$k.studies)
max.k.per.study <- rep(5, cond$k.studies)
# 11.09.2018 - I think we will need to change this part to create right skewed
# k's that can be as large as something like 500 -from Senior et al. (2016)
k.per.study <- mapply(gen.k.per.group, min.k=min.k.per.study, max.k=max.k.per.study)
study <- rep(1:cond$k.studies, times=k.per.study)
gen.k.per.group <- function(min.k, max.k)
round(runif(1, min.k, max.k),0)
### simulate k for each study
min.k.per.study <- rep(1, cond$k.studies)
max.k.per.study <- rep(5, cond$k.studies)
# 11.09.2018 - I think we will need to change this part to create right skewed
# k's that can be as large as something like 500 -from Senior et al. (2016)
k.per.study <- mapply(gen.k.per.group, min.k=min.k.per.study, max.k=max.k.per.study)
study <- rep(1:cond$k.studies, times=k.per.study)
### total number of estimates
k <- length(study)
species <- c(1:cond$k.species)
tmp <- rbeta(n = k - cond$k.species, shape1 = 2, shape2 = 2)
tmp <- tmp * (cond$k.species - 1)
tmp <- round(tmp) + 1
species <- c(species, tmp)
species.phylo <- species
### simulate tree
tree <- rtree(cond$k.species, tip.label=1:cond$k.species)
# tree <- chronopl(tree, lambda=1)
tree <- compute.brlen(tree, power = cond$tree.power)
plot(tree)
#plot(tree)
P <- vcv(tree, corr=TRUE)
P <- P[order(as.numeric(rownames(P))), order(as.numeric(rownames(P)))]
P
### simulate random effects
u.s <- rep(rnorm(cond$k.studies, 0, sqrt(cond$sigma2.s)), times=k.per.study)
u.e <- rnorm(k, 0, sqrt(cond$sigma2.e))
u.n <- rnorm(cond$k.species, 0, sqrt(cond$sigma2.n))[species]
u.p <- mvrnorm(1, mu=rep(0,cond$k.species), Sigma=cond$sigma2.p*P)[species]
### 21.08.2018 - Ozan tried some changes here. We may need to change the
### parameters of the beta distribution to generate more appropriate sampling
### variances. The original set of parameters were a = 2, b = 5.
### simulate sampling variances and sampling errors
# vi <- rbeta(k, 2, 5) * cond$vi.fac  # we can think vi as a mean difference
vi <- rbeta(k, 2, 20) * cond$vi.fac  # we can think vi as a mean difference
ei <- rnorm(k, 0, sqrt(vi))
yi <- rep(cond$beta, k) + u.s + u.e + u.n + u.p + ei
### estimate ids
id <- 1:k
mod3 <- try(rma.mv(yi, vi, random = ~ 1 | id, control=control3), silent = TRUE)
inherits(mod3, "try-error")
mod6 <- try(rma.mv(yi, vi, random = ~ 1 | study/id, control=control6), silent = TRUE)
inherits(mod6, "try-error")
mod8 <- try(rma.mv(yi, vi, random = list(~ 1 | species, ~ 1 | study/id), control=control8), silent = TRUE)
inherits(mod8, "try-error")
mod15 <- try(rma.mv(yi, vi, random = list(~ 1 | species, ~ 1 | species.phylo, ~ 1 | study/id), R = list(species.phylo=P), control=control15), silent = TRUE)
inherits(mod15, "try-error")
AIC(mod3)
AIC(mod5)
AIC(mod6)
AIC(mod8)
AIC(mod15)
AIC.rma(mod3)
AIC.rma(mod6)
AIC.rma(mod8)
AIC.rma(mod15)
AIC(mod15, correct = TRUE)
AIC.rma(mod15, correct = TRUE)
?AIC
AIC
getAnywhere(AIC)
AIC.rma
library(poolR)
pnorm(0)
log(pnorm(0))
pnorm(0, log.p = TRUE)
pnorm(0, log.p = TRUE) == log(pnorm(0))
identical(pnorm(0, log.p = TRUE), log(pnorm(0)))
identical(pnorm(9.876, log.p = TRUE), log(pnorm(9.876)))
identical(pnorm(4.9, log.p = TRUE), log(pnorm(4.9)))
f1=jitter(sample(c(2,3),1));f2=jitter(sample(c(2,3),1));f3=jitter(sample(c(2,3),1));f4=jitter(sample(c(2,3),1))
d1=runif(1,0,1e-02);d2=runif(1,0,1e-02);d3=runif(1,0,1e-02);d4=runif(1,0,1e-02)
p1=runif(1,0,pi);p2=runif(1,0,pi);p3=runif(1,0,pi);p4=runif(1,0,pi)
xt = function(t) exp(-d1*t)*sin(t*f1+p1)+exp(-d2*t)*sin(t*f2+p2)
yt = function(t) exp(-d3*t)*sin(t*f3+p3)+exp(-d4*t)*sin(t*f4+p4)
t=seq(1, 100, by=.001)
dat=data.frame(t=t, x=xt(t), y=yt(t))
with(dat, plot(x,y, type="l", xlim =c(-2,2), ylim =c(-2,2), xlab = "", ylab = "", xaxt='n', yaxt='n'))
setwd("./Desktop/Ozan/MU/Products/R/Combining P-Values Package/poolR/")
fisher <- function(p, adjust = "none", m, R, size = 10000, seed, type = 2,
emp.loop = FALSE, emp.step, ...) {
k <- length(p)
# if m is provided by the user, then we don't need to check the adjustment method.
if (!missing(m)) {
m       <- m
adjust  <- paste0(m, " (user defined)")
testStat <- -2 * sum(log(p))
testStat <- testStat * (m / k)
pooled.p <- pchisq(testStat, df = 2 * m, lower.tail = FALSE)
# warning the user if the user-defined m is larger than the number of p-values.
if (m > k)
warning("the user-defined effective number of test is larger than the number of p-values that were combined.")
} else {
# first, if the adjust is not given, it will be set to "none".
if (missing(adjust))
adjust <- "none"
# now, checking the adjust argument.
if (!adjust %in% c("none", "nyholt", "liji", "gao", "galwey", "empirical", "generalized"))
stop("adjust argument is not given correctly. Please see ?fisher for the correct options for adjust.")
if (adjust == "none") {
testStat  <- -2 * sum(log(p))
pooled.p  <- pchisq(testStat, df = 2*k, lower.tail = FALSE)
adjust    <- "none"
} else if (adjust %in% c("nyholt", "liji", "gao", "galwey")) {
m       <- meff(R = R, method = adjust)
adjust  <- paste0("meff (", adjust, ")")
testStat <- -2 * sum(log(p))
testStat <- testStat * (m / k)
pooled.p <- pchisq(testStat, df = 2 * m, lower.tail = FALSE)
} else if (adjust == "generalized") {
covs <- R
expx2 <- 2 * k
varx2 <- sum(covs)
fval <- 2 * expx2^2 / varx2
cval <- varx2 / (2 * expx2)
testStat  <- -2 * sum(log(p))
testStat  <- testStat/cval
pooled.p  <- pchisq(testStat, df = fval, lower.tail = FALSE)
adjust    <- "Brown"
} else if (adjust == "empirical") {
# checking if the user wants to use a stepwise algorithm for empirical adjustment.
if (!missing(emp.step)) {
# checking if emp.step is a list.
if (!is.list(emp.step))
stop("emp.dist should be a list.")
# checking if there are two vectors in the emp.step.
if (!length(emp.step) == 2)
stop("emp.dist should include two lists. Please see ?fisher.")
# checking if the lengths of the vectors in the emp.step are correct.
if (!(length(emp.step[[1]]) - length(emp.step[[2]])) %in% c(-1, 1))
stop("the lengths of the vectors in emp.step are not correct. Please see ?fisher.")
# checking if the vectors have names.
if (is.null(names(emp.step))) {
# if they don't have names, they will be named.
names(emp.step)[which.max(unlist(lapply(emp.step, length)))] <- "size"
names(emp.step)[which.min(unlist(lapply(emp.step, length)))] <- "thres"
} else {
# if the names of the vectors are not correct, they will be corrected.
if (!all(names(emp.step) %in% c("size", "thres"))) {
names(emp.step)[which.max(unlist(lapply(emp.step, length)))] <- "size"
names(emp.step)[which.min(unlist(lapply(emp.step, length)))] <- "thres"
}
}
# setting the seed before starting to generate sets to obtain mutually exclusive sets.
if (!missing(seed))
set.seed(seed)
for (i in 1:length(emp.step$thres)) {
size      <- emp.step$size[i]
emp.dist  <- empirical(R = R, method = "fisher", type = type, size = size,
emp.loop = emp.loop)
testStat.tmp <- -2 * sum(log(p))
pooled.p.tmp <- (sum(emp.dist >= testStat) + 1) / (size + 1)
if (pooled.p.tmp > emp.step$thres[i]) {
testStat  <- testStat.tmp
pooled.p  <- pooled.p.tmp
adjust    <- "empirical"
break
}
}
# if the threshold could not be achieved in the loop, then we are going
# to use the largest sample size.
if (!exists("pooled.p")) {
size      <- max(emp.step$size)
emp.dist  <- empirical(R = R, method = "fisher", type = type, size = size,
seed = seed, emp.loop = emp.loop)
testStat  <- -2 * sum(log(p))
pooled.p  <- (sum(emp.dist >= testStat) + 1) / (size + 1)
adjust    <- "empirical"
}
} else {
tmp <- list(...)
# if an empirical distribution is not provided by the user, we will use
# empirical() to generate an empirical distribution.
if (is.null(tmp$emp.dis)) {
emp.dist <- empirical(R = R, method = "fisher", type = type, size = size,
seed = seed, emp.loop = emp.loop)
} else { # otherwise, the function will use the user-given empirical distribution.
emp.dist <- tmp$emp.dist
}
testStat  <- -2 * sum(log(p))
pooled.p  <- (sum(emp.dist >= testStat) + 1) / (size + 1)
adjust    <- "empirical"
}
}
}
res <- list(p = pooled.p, testStat = testStat, adjust = adjust)
class(res) <- "combP"
return(res)
}
setwd("./R")
ls()
dir()
source("brown1.r")
source("brown2.r")
source("brown2.R")
library(MASS)
rho <- 0.3
m <- 5
m <- 10
R <- matrix(rho, m, m)
diag(R) <- 1
R
z <- mvrnorm(1, mu = rep(m, 0), Sigma = R)
z <- mvrnorm(1, mu = rep(0, m), Sigma = R)
p1 <- pnorm(z)
p2 <- 2 * pnorm(abs(z), lower.tail = FALSE)
p1
p2
fisher(p1, adjust = "generalized", R = R)
fisher(p1, adjust = "generalized", R = brown1(R))
fisher(p1, adjust = "generalized", R = brown2(R))
source("print.combP.r")
fisher(p1, adjust = "generalized", R = brown2(R))
?match.arg
rm(list = ls())
binotest <- function(p, adjust = "none", m, R, alpha = 0.05, size = 10000, seed,
type = 2, emp.loop = FALSE, emp.step, ...) {
adjust <- match.arg(adjust, c("none", "nyholt", "liji", "gao", "galwey", "empirical"))
k <- length(p)
r <- sum(p <= alpha)
# if m is provided by the user, then we don't need to check the adjustment method.
if(!missing(m)) {
m <- m
adjust <- paste0(m, " (user defined)")
testStat <- dbinom(round(r * m / k), m, alpha)
pooled.p <- sum(dbinom(round(r * m / k):m, m, alpha))
# warning the user if the user-defined m is larger than the number of p-values.
if(m > k)
warning("the user-defined effective number of test is larger than the number of p-values that were combined.")
} else {
# if m is not provided by the user, then the functions will use adjust argument.
# checking if the adjust argument is given correctly.
# first, if the adjust is not given, it will be set to "none".
if(missing(adjust))
adjust <- "none"
# now, checking the adjust argument.
if(!adjust %in% c("none", "nyholt", "liji", "gao", "galwey", "empirical"))
stop("adjust argument is not given correctly. Please see ?binotest for the correct options for adjust.")
if (adjust == "none") {
testStat <- dbinom(r, k, alpha)
pooled.p <- sum(dbinom(r:k, k, alpha))
adjust <- "none"
} else if (adjust %in% c("nyholt", "liji", "gao", "galwey")) {
m <- meff(R = R, method = adjust)
adjust <- paste0("meff (", adjust, ")")
testStat <- dbinom(round(r * m / k), m, alpha)
pooled.p <- sum(dbinom(round(r * m / k):m, m, alpha))
} else if (adjust == "empirical") {
# checking if the user wants to use a stepwise algorithm for empirical adjustment.
if (!missing(emp.step)) {
# checking if emp.step is a list.
if (!is.list(emp.step))
stop("emp.dist should be a list.")
# checking if there are two vectors in the emp.step.
if (!length(emp.step) == 2)
stop("emp.dist should include two lists. Please see ?binotest.")
# checking if the lengths of the vectors in the emp.step are correct.
if (!(length(emp.step[[1]]) - length(emp.step[[2]])) %in% c(-1, 1))
stop("the lengths of the vectors in emp.step are not correct. Please see ?binotest.")
# checking if the vectors have names.
if (is.null(names(emp.step))) {
# if they don't have names, they will be named.
names(emp.step)[which.max(unlist(lapply(emp.step, length)))] <- "size"
names(emp.step)[which.min(unlist(lapply(emp.step, length)))] <- "thres"
} else {
# if the names of the vectors are not correct, they will be corrected.
if (!all(names(emp.step) %in% c("size", "thres"))) {
names(emp.step)[which.max(unlist(lapply(emp.step, length)))] <- "size"
names(emp.step)[which.min(unlist(lapply(emp.step, length)))] <- "thres"
}
}
# setting the seed before starting to generate sets to obtain mutually exclusive sets.
if (!missing(seed))
set.seed(seed)
for (i in 1:length(emp.step$thres)) {
size      <- emp.step$size[i]
emp.dist  <- empirical(R = R, method = "binotest", type = type, size = size,
emp.loop = emp.loop)
testStat.tmp <- dbinom(r, k, alpha)
pooled.p.tmp <- (sum(emp.dist <= testStat) + 1) / (size + 1)
if (pooled.p.tmp > emp.step$thres[i]) {
testStat  <- testStat.tmp
pooled.p  <- pooled.p.tmp
adjust    <- "empirical"
break
}
}
# if the threshold could not be achieved in the loop, then we are going
# to use the largest sample size.
if (!exists("pooled.p")) {
size      <- max(emp.step$size)
emp.dist  <- empirical(R = R, method = "binotest", type = type, size = size,
seed = seed, emp.loop = emp.loop)
testStat  <- dbinom(r, k, alpha)
pooled.p  <- (sum(emp.dist <= testStat) + 1) / (size + 1)
adjust    <- "empirical"
}
} else {
tmp <- list(...)
# if an empirical distribution is not provided by the user, we will use
# empirical() to generate an empirical distribution.
if (is.null(tmp$emp.dis)) {
emp.dist <- empirical(R = R, method = "binotest", type = type, size = size,
seed = seed, emp.loop = emp.loop)
} else { # otherwise, the function will use the user-given empirical distribution.
emp.dist <- tmp$emp.dist
}
testStat  <- dbinom(r, k, alpha)
pooled.p  <- (sum(emp.dist <= testStat) + 1) / (size + 1)
adjust    <- "empirical"
}
}
}
res <- list(p = pooled.p, testStat = testStat, adjust = adjust)
class(res) <- "combP"
return(res)
}
p <- runif(10)
binotest(p)
binotest(p, adjust = "no")
binotest(p, adjust = "ny")
